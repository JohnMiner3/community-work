{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#\r\n",
        "# Name:         nb-spark-write-parquet-files\r\n",
        "#\r\n",
        "\r\n",
        "#\r\n",
        "# Design Phase:\r\n",
        "#     Author:   John Miner\r\n",
        "#     Date:     09-15-2022\r\n",
        "#     Purpose:  Read for lake database and write to parquet files\r\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {
        "microsoft": {
          "language": "python"
        }
      },
      "source": [
        "%%pyspark\n",
        "\n",
        "#\n",
        "#  Save parquet file - /currency\n",
        "#\n",
        "\n",
        "path = 'abfss://sc4adls2030@sa4adls2030.dfs.core.windows.net/synapse/parquet-files/DimCurrency'\n",
        "sql = \"SELECT * FROM saleslt.dim_currency\"\n",
        "df = spark.sql(sql)\n",
        "df.repartition(1).write.parquet(path)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      },
      "source": [
        "%%pyspark\r\n",
        "\r\n",
        "#\r\n",
        "#  Save parquet file - /customer\r\n",
        "#\r\n",
        "\r\n",
        "path = 'abfss://sc4adls2030@sa4adls2030.dfs.core.windows.net/synapse/parquet-files/DimCustomer'\r\n",
        "sql = \"SELECT * FROM saleslt.dim_customer\"\r\n",
        "df = spark.sql(sql)\r\n",
        "df.repartition(1).write.parquet(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      },
      "source": [
        "%%pyspark\r\n",
        "\r\n",
        "#\r\n",
        "#  Save parquet file - /date\r\n",
        "#\r\n",
        "\r\n",
        "path = 'abfss://sc4adls2030@sa4adls2030.dfs.core.windows.net/synapse/parquet-files/DimDate'\r\n",
        "sql = \"SELECT * FROM saleslt.dim_date\"\r\n",
        "df = spark.sql(sql)\r\n",
        "df.repartition(1).write.parquet(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#\r\n",
        "#  Save parquet file - /geography\r\n",
        "#\r\n",
        "\r\n",
        "path = 'abfss://sc4adls2030@sa4adls2030.dfs.core.windows.net/synapse/parquet-files/DimGeography'\r\n",
        "sql = \"SELECT * FROM saleslt.dim_geography\"\r\n",
        "df = spark.sql(sql)\r\n",
        "df.repartition(1).write.parquet(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#\r\n",
        "#  Save parquet file - /product\r\n",
        "#\r\n",
        "\r\n",
        "path = 'abfss://sc4adls2030@sa4adls2030.dfs.core.windows.net/synapse/parquet-files/DimProduct'\r\n",
        "sql = \"SELECT * FROM saleslt.dim_product\"\r\n",
        "df = spark.sql(sql)\r\n",
        "df.repartition(1).write.parquet(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#\r\n",
        "#  Save parquet file - /product-category\r\n",
        "#\r\n",
        "\r\n",
        "path = 'abfss://sc4adls2030@sa4adls2030.dfs.core.windows.net/synapse/parquet-files/DimProductCategory'\r\n",
        "sql = \"SELECT * FROM saleslt.dim_product_category\"\r\n",
        "df = spark.sql(sql)\r\n",
        "df.repartition(1).write.parquet(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#\r\n",
        "#  Save parquet file - /product-subcategory\r\n",
        "#\r\n",
        "\r\n",
        "path = 'abfss://sc4adls2030@sa4adls2030.dfs.core.windows.net/synapse/parquet-files/DimProductSubcategory'\r\n",
        "sql = \"SELECT * FROM saleslt.dim_product_subcategory\"\r\n",
        "df = spark.sql(sql)\r\n",
        "df.repartition(1).write.parquet(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#\r\n",
        "#  Save parquet file - /sales-reason\r\n",
        "#\r\n",
        "\r\n",
        "path = 'abfss://sc4adls2030@sa4adls2030.dfs.core.windows.net/synapse/parquet-files/DimSalesReason'\r\n",
        "sql = \"SELECT * FROM saleslt.dim_sales_reason\"\r\n",
        "df = spark.sql(sql)\r\n",
        "df.repartition(1).write.parquet(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#\r\n",
        "#  Save parquet file - /sales-territory\r\n",
        "#\r\n",
        "\r\n",
        "path = 'abfss://sc4adls2030@sa4adls2030.dfs.core.windows.net/synapse/parquet-files/DimSalesTerritory'\r\n",
        "sql = \"SELECT * FROM saleslt.dim_sales_territory\"\r\n",
        "df = spark.sql(sql)\r\n",
        "df.repartition(1).write.parquet(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#\r\n",
        "#  Save parquet file - /fact-internet-sales\r\n",
        "#\r\n",
        "\r\n",
        "path = 'abfss://sc4adls2030@sa4adls2030.dfs.core.windows.net/synapse/parquet-files/FactInternetSales'\r\n",
        "sql = \"SELECT * FROM saleslt.fact_internet_sales\"\r\n",
        "df = spark.sql(sql)\r\n",
        "df.repartition(4).write.parquet(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#\r\n",
        "#  Save parquet file - /fact-internet-sales-reason\r\n",
        "#\r\n",
        "\r\n",
        "path = 'abfss://sc4adls2030@sa4adls2030.dfs.core.windows.net/synapse/parquet-files/FactInternetSalesReason'\r\n",
        "sql = \"SELECT * FROM saleslt.fact_internet_sales_reason\"\r\n",
        "df = spark.sql(sql)\r\n",
        "df.repartition(1).write.parquet(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    }
  }
}